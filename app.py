# ==========================================================
#  app.py - æ­©è¡Œåˆ†æã‚¢ãƒ—ãƒªã®ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚°ãƒ©ãƒ 
# ==========================================================
import streamlit as st
from scipy.signal import find_peaks
import cv2
import mediapipe as mp
import math
import numpy as np
import matplotlib.pyplot as plt
import os
import tempfile
import japanize_matplotlib

# --- ãƒ¡ã‚¤ãƒ³ã®åˆ†æãƒ­ã‚¸ãƒƒã‚¯ã‚’é–¢æ•°åŒ– ---
def analyze_walking(video_path, progress_bar, status_text):
    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(static_image_mode=False, model_complexity=1, min_detection_confidence=0.5, min_tracking_confidence=0.5)
    mp_drawing = mp.solutions.drawing_utils

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        st.error("ã‚¨ãƒ©ãƒ¼: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None, None

    fps = cap.get(cv2.CAP_PROP_FPS) or 30
    all_angles, all_images = [], []
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    for frame_count in range(total_frames):
        success, image = cap.read()
        if not success: break
        
        progress_percentage = (frame_count + 1) / total_frames
        progress_bar.progress(progress_percentage)
        status_text.text(f"ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†æä¸­: {frame_count + 1}/{total_frames}")

        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = pose.process(image_rgb)
        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,
            landmark_drawing_spec=mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),
            connection_drawing_spec=mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2))
        
        current_angle = all_angles[-1] if all_angles else 0
        if results.pose_landmarks:
            landmarks = results.pose_landmarks.landmark
            try:
                p_ls, p_rs = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value], landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value]
                p_lh, p_rh = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value], landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value]
                shoulder_center_x, shoulder_center_y = (p_ls.x + p_rs.x) / 2, (p_ls.y + p_rs.y) / 2
                hip_center_x, hip_center_y = (p_lh.x + p_rh.x) / 2, (p_lh.y + p_rh.y) / 2
                v_x, v_y = shoulder_center_x - hip_center_x, hip_center_y - shoulder_center_y
                angle = -math.degrees(math.atan2(v_x, v_y))
                if abs(angle) < 45: current_angle = angle
            except Exception: pass
        
        all_angles.append(current_angle)
        all_images.append(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)) # Matplotlibç”¨ã«RGBã§ä¿å­˜
    
    status_text.text("åˆ†æå®Œäº†ã€‚ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆä¸­...")
    cap.release()

    summary = {}
    if len(all_angles) > int(fps):
        angles_np = np.array(all_angles)
        CORE_SWING_PERCENTAGE_THRESHOLD = 0.7 
        peak_distance = int(fps * 0.4); peak_height = 2.0
        left_peak_indices, _ = find_peaks(angles_np, height=peak_height, distance=peak_distance)
        right_peak_indices, _ = find_peaks(-angles_np, height=peak_height, distance=peak_distance)
        all_core_swing_angles_left, all_core_swing_angles_right = [], []

        for p_idx in left_peak_indices:
            peak_value = angles_np[p_idx]; threshold = peak_value * CORE_SWING_PERCENTAGE_THRESHOLD
            start_idx, end_idx = p_idx, p_idx
            while start_idx > 0 and angles_np[start_idx-1] > threshold: start_idx -= 1
            while end_idx < len(angles_np)-1 and angles_np[end_idx+1] > threshold: end_idx += 1
            all_core_swing_angles_left.extend(angles_np[start_idx:end_idx+1])

        for p_idx in right_peak_indices:
            peak_value = angles_np[p_idx]; threshold = peak_value * CORE_SWING_PERCENTAGE_THRESHOLD
            start_idx, end_idx = p_idx, p_idx
            while start_idx > 0 and angles_np[start_idx-1] < threshold: start_idx -= 1
            while end_idx < len(angles_np)-1 and angles_np[end_idx+1] < threshold: end_idx += 1
            all_core_swing_angles_right.extend(angles_np[start_idx:end_idx+1])

        summary = {
            'avg_swing_core_left': np.mean(all_core_swing_angles_left) if all_core_swing_angles_left else 0,
            'avg_swing_core_right': np.mean(all_core_swing_angles_right) if all_core_swing_angles_right else 0,
        }
    else:
        return None, None

    status_text.text("çµæœã®å‹•ç”»ã‚’ç”Ÿæˆä¸­...")
    frame_h, frame_w, _ = all_images[0].shape
    graph_h, summary_h = 350, 300
    final_h, final_w = frame_h + graph_h + summary_h, frame_w
    
    temp_output = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
    output_video_path = temp_output.name
    out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (final_w, final_h))
    
    fig_s, ax_s = plt.subplots(figsize=(final_w/100, summary_h/100), dpi=100, facecolor='#1E1E1E')
    ax_s.axis('off'); ax_s.set_title('æ­©è¡Œåˆ†æã‚µãƒãƒªãƒ¼', color='white', fontsize=28, pad=25, weight='bold')
    texts_left = [(0.1, 0.65, "å¹³å‡å·¦ã‚¹ã‚¤ãƒ³ã‚°å´å±ˆ:", '#33FF57', 28), (0.1, 0.35, "å¹³å‡å³ã‚¹ã‚¤ãƒ³ã‚°å´å±ˆ:", '#33A8FF', 28)]
    texts_right = [(0.9, 0.65, f"{summary['avg_swing_core_left']:.2f} åº¦", '#33FF57', 28), (0.9, 0.35, f"{abs(summary['avg_swing_core_right']):.2f} åº¦", '#33A8FF', 28)]
    for x, y, text, color, size in texts_left: ax_s.text(x, y, text, color=color, fontsize=size, ha='left', va='center', transform=ax_s.transAxes, weight='bold')
    for x, y, text, color, size in texts_right: ax_s.text(x, y, text, color=color, fontsize=size, ha='right', va='center', transform=ax_s.transAxes, weight='bold')
    fig_s.canvas.draw(); summary_img = cv2.cvtColor(np.asarray(fig_s.canvas.buffer_rgba()), cv2.COLOR_RGBA2BGR); plt.close(fig_s)
    
    time_stamps = np.arange(len(all_angles)) / fps
    for i, rgb_image in enumerate(all_images):
        progress_percentage = (i + 1) / len(all_images)
        if i % 10 == 0: # 10ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«é€²æ—ã‚’æ›´æ–°
            progress_bar.progress(progress_percentage)

        fig_g, ax_g = plt.subplots(figsize=(final_w/100, graph_h/100), dpi=100)
        fig_g.set_facecolor('#1E1E1E'); ax_g.set_facecolor('#1E1E1E')
        ax_g.tick_params(colors='white', labelsize=14)
        for spine in ax_g.spines.values(): spine.set_edgecolor('white')
        ax_g.plot(time_stamps, all_angles, color='#00FFFF', lw=2.5)
        ax_g.plot(time_stamps[i], all_angles[i], 'o', markersize=12, color='#FF1493', mec='white')
        ax_g.axhline(0, color='red', linestyle='--', lw=2)
        ax_g.set_title('ä½“å¹¹ã®å´å±ˆï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰', color='white', fontsize=24, pad=20)
        ax_g.set_xlabel('æ™‚é–“ (ç§’)', color='white', fontsize=18); ax_g.set_ylabel('å´å±ˆè§’åº¦ (åº¦)', color='white', fontsize=18)
        y_abs_max = max(abs(val) for val in all_angles) if all_angles else 10
        y_limit = max(y_abs_max, 10) * 1.2
        ax_g.set_ylim(-y_limit, y_limit)
        ax_g.text(1.02, 0.9, 'â–² å·¦å´å±ˆ', transform=ax_g.transAxes, color='#33FF57', va='center', fontsize=16, weight='bold')
        ax_g.text(1.02, 0.1, 'â–¼ å³å´å±ˆ', transform=ax_g.transAxes, color='#33A8FF', va='center', fontsize=16, weight='bold')
        ax_g.grid(True, linestyle=':', color='gray', alpha=0.7); fig_g.tight_layout(pad=2.5)
        fig_g.canvas.draw(); graph_img = cv2.cvtColor(np.asarray(fig_g.canvas.buffer_rgba()), cv2.COLOR_RGBA2BGR); plt.close(fig_g)
        out.write(cv2.vconcat([cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR), graph_img, summary_img])) # BGRã«æˆ»ã—ã¦æ›¸ãè¾¼ã¿
    
    out.release()
    status_text.text("å®Œäº†ï¼")
    return output_video_path, summary

# --- Streamlitã®UIéƒ¨åˆ† ---
st.set_page_config(page_title="æ­©è¡Œåˆ†æã‚¢ãƒ—ãƒª", layout="wide")
st.title("ğŸš¶â€â™‚ï¸ æ­©è¡Œåˆ†æã‚¢ãƒ—ãƒª")
st.write("---")
st.write("ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã§æ’®å½±ã—ãŸæ­©è¡Œå‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã ã‘ã§ã€ä½“å¹¹ã®å´å±ˆã‚’è‡ªå‹•ã§åˆ†æã—ã€ã‚°ãƒ©ãƒ•ä»˜ãã®å‹•ç”»ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")

uploaded_file = st.file_uploader("ã“ã“ã«å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆmp4, movãªã©ï¼‰ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—ã—ã¦ãã ã•ã„", type=["mp4", "mov", "avi", "m4v"])

if uploaded_file is not None:
    with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1]) as tfile:
        tfile.write(uploaded_file.read())
        temp_video_path = tfile.name

    st.video(temp_video_path)

    if st.button("ã“ã®å‹•ç”»ã‚’åˆ†æã™ã‚‹", type="primary"):
        progress_bar = st.progress(0.0)
        status_text = st.empty()
        
        with st.spinner('åˆ†æã‚’å®Ÿè¡Œä¸­ã§ã™...ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚'):
            output_video_path, summary = analyze_walking(temp_video_path, progress_bar, status_text)

        if output_video_path and summary:
            st.success("ğŸ‰ åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            st.balloons()
            
            st.subheader("åˆ†æçµæœã‚µãƒãƒªãƒ¼")
            col1, col2 = st.columns(2)
            col1.metric(label="å¹³å‡å·¦ã‚¹ã‚¤ãƒ³ã‚°å´å±ˆ", value=f"{summary['avg_swing_core_left']:.2f} åº¦")
            col2.metric(label="å¹³å‡å³ã‚¹ã‚¤ãƒ³ã‚°å´å±ˆ", value=f"{abs(summary['avg_swing_core_right']):.2f} åº¦")

            st.subheader("åˆ†æçµæœãƒ“ãƒ‡ã‚ª")
            # Streamlitã§æ­£ã—ãè¡¨ç¤ºã™ã‚‹ãŸã‚ã«å‹•ç”»ã‚’å†èª­ã¿è¾¼ã¿
            video_file = open(output_video_path, 'rb')
            video_bytes = video_file.read()
            st.video(video_bytes)

            st.download_button(
                label="çµæœã®ãƒ“ãƒ‡ã‚ªã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=video_bytes,
                file_name="result.mp4",
                mime="video/mp4"
            )
            
            os.remove(output_video_path)
        else:
            st.error("åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚åˆ¥ã®å‹•ç”»ã§è©¦ã™ã‹ã€å‹•ç”»ãŒçŸ­ã™ããªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        os.remove(temp_video_path)